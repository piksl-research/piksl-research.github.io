<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | PIKSL </title> <meta name="author" content="Blake Dewey"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link id="favicon" rel="shortcut icon" href="/assets/img/favicon.ico?a1fc58f13d443104ec41426e5ba35521" data-href="/assets/img/favicon.ico?a1fc58f13d443104ec41426e5ba35521" data-href-dark="/assets/img/favicon-dark.ico?47f55371e39af9c3f51fbb2de17c001d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://piksl-research.github.io/publications/"> <script src="/assets/js/theme.js?c3d44075d228287f39cf9e34ac17f1ec"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> PIKSL </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/courses/">courses </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description"></p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div id="Dewey823" class="col-sm-10"> <div class="title">Super-Resolution in Clinically Available Spinal Cord MRIs Enables Automated Atrophy Analysis</div> <div class="author"> <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, <a href="https://sremedios.github.io/" rel="external nofollow noopener" target="_blank">Samuel W. Remedios</a>, Muraleetharan Sanjayan, Nicole Bou Rjeily, Alexandra Zambriczki Lee, Chelsea Wyche, Safiya Duncan, Jerry L. Prince, Peter A. Calabresi, Kathryn C. Fitzgerald, and Ellen M. Mowry </div> <div class="periodical"> <em>American Journal of Neuroradiology</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3174/ajnr.A8526" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.3174/ajnr.A8526" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:fPk4N6BV_jEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>BACKGROUND AND PURPOSE: Measurement of the mean upper cervical cord area (MUCCA) is an important biomarker in the study of neurodegeneration. However, dedicated high-resolution (HR) scans of the cervical spinal cord are rare in standard-of-care imaging due to timing and clinical usability. Most clinical cervical spinal cord imaging is sagittally acquired in 2D with thick slices and anisotropic voxels. As a solution, previous work describes HR T1-weighted brain imaging for measuring the upper cord area, but this is still not common in clinical care.MATERIALS AND METHODS: We propose using a zero-shot super-resolution technique, synthetic multi-orientation resolution enhancement (SMORE), already validated in the brain, to enhance the resolution of 2D-acquired scans for upper cord area calculations. To incorporate super-resolution in spinal cord analysis, we validate SMORE against HR research imaging and in a real-world longitudinal data analysis.RESULTS: Super-resolved (SR) images reconstructed by using SMORE showed significantly greater similarity to the ground truth than low-resolution (LR) images across all tested resolutions (P &lt; .001 for all resolutions in peak signal-to-noise ratio [PSNR] and mean structural similarity [MSSIM]). MUCCA results from SR scans demonstrate excellent correlation with HR scans (r &gt; 0.973 for all resolutions) compared with LR scans. Additionally, SR scans are consistent between resolutions (r &gt; 0.969), an essential factor in longitudinal analysis. Compared with clinical outcomes such as walking speed or disease severity, MUCCA values from LR scans have significantly lower correlations than those from HR scans. SR results have no significant difference. In a longitudinal real-world data set, we show that these SR volumes can be used in conjunction with T1-weighted brain scans to show a significant rate of atrophy (-0.790, P = .020 versus -0.438, P = .301 with LR).CONCLUSIONS: Super-resolution is a valuable tool for enabling large-scale studies of cord atrophy, as LR images acquired in clinical practice are common and available.9HPT9-hole peg testCSCcervical spinal cordEDSSExpanded Disability Status ScaleHRhigh-resolutionLRlow-resolutionMSFCMS functional compositeMSSIMmean structural similarityMUCCAmean upper cervical cord areaPMJpontomedullary junctionPSNRpeak signal-to-noise ratioSMOREsynthetic multi-orientation resolution enhancementSRsuper-resolvedT25FWtimed 25-foot walk</p> </div> </div> </div> </li> <li> <div class="row"> <div id="remedios2025eclareefficientcrossplanarlearning" class="col-sm-10"> <div class="title">ECLARE: Efficient cross-planar learning for anisotropic resolution enhancement</div> <div class="author"> <a href="https://sremedios.github.io/" rel="external nofollow noopener" target="_blank">Samuel W. Remedios</a>, Shuwen Wei, Shuo Han, Jinwei Zhang, Aaron Carass, Kurt G. Schilling, Dzung L. Pham, Jerry L. Prince, and <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a> </div> <div class="periodical"> 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.48550/arXiv.2503.11787" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2503.11787" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.48550/arXiv.2503.11787" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:9ZlFYXVOiuMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In clinical imaging, magnetic resonance (MR) image volumes are often acquired as stacks of 2D slices with decreased scan times, improved signal-to-noise ratio, and image contrasts unique to 2D MR pulse sequences. While this is sufficient for clinical evaluation, automated algorithms designed for 3D analysis perform poorly on multi-slice 2D MR volumes, especially those with thick slices and gaps between slices. Super-resolution (SR) methods aim to address this problem, but previous methods do not address all of the following: slice profile shape estimation, slice gap, domain shift, and non-integer or arbitrary upsampling factors. In this paper, we propose ECLARE (Efficient Cross-planar Learning for Anisotropic Resolution Enhancement), a self-SR method that addresses each of these factors. ECLARE uses a slice profile estimated from the multi-slice 2D MR volume, trains a network to learn the mapping from low-resolution to high-resolution in-plane patches from the same volume, and performs SR with anti-aliasing. We compared ECLARE to cubic B-spline interpolation, SMORE, and other contemporary SR methods. We used realistic and representative simulations so that quantitative performance against ground truth can be computed, and ECLARE outperformed all other methods in both signal recovery and downstream tasks. Importantly, as ECLARE does not use external training data it cannot suffer from domain shift between training and testing.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div id="park_development_2024" class="col-sm-10"> <div class="title">Development of Medical Imaging Data Standardization for Imaging-Based Observational Research: OMOP Common Data Model Extension</div> <div class="author"> Woo Yeon Park, Kyulee Jeon, Teri Sippel Schmidt, Haridimos Kondylakis, Tarik Alkasab, <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, Seng Chan You, and Paul Nagy </div> <div class="periodical"> <em>Journal of Imaging Informatics in Medicine</em>, Apr 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s10278-024-00982-6" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10278-024-00982-6" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:_Qo2XoVZTnwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The rapid growth of artificial intelligence (AI) and deep learning techniques require access to large inter-institutional cohorts of data to enable the development of robust models, e.g., targeting the identification of disease biomarkers and quantifying disease progression and treatment efficacy. The Observational Medical Outcomes Partnership Common Data Model (OMOP CDM) has been designed to accommodate a harmonized representation of observational healthcare data. This study proposes the Medical Imaging CDM (MI-CDM) extension, adding two new tables and two vocabularies to the OMOP CDM to address the structural and semantic requirements to support imaging research. The tables provide the capabilities of linking DICOM data sources as well as tracking the provenance of imaging features derived from those images. The implementation of the extension enables phenotype definitions using imaging features and expanding standardized computable imaging biomarkers. This proposal offers a comprehensive and unified approach for conducting imaging research and outcome studies utilizing imaging features.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div id="10.1007/978-3-031-44689-4_12" class="col-sm-10"> <div class="title">Self-Supervised Super-Resolution for Anisotropic MR Images with and Without Slice Gap</div> <div class="author"> <a href="https://sremedios.github.io/" rel="external nofollow noopener" target="_blank">Samuel W. Remedios</a>, Shuo Han, Lianrui Zuo, Aaron Carass, Dzung L. Pham, Jerry L. Prince, and <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a> </div> <div class="periodical"> <em>In Simulation and Synthesis in Medical Imaging</em>, Apr 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-44689-4_12" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-031-44689-4_12" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:r0BpntZqJG4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Magnetic resonance (MR) images are often acquired as multi-slice volumes to reduce scan time and motion artifacts while improving signal-to-noise ratio. These slices often are thicker than their in-plane resolution and sometimes are acquired with gaps between slices. Such thick-slice image volumes (possibly with gaps) can impact the accuracy of volumetric analysis and 3D methods. While many super-resolution (SR) methods have been proposed to address thick slices, few have directly addressed the slice gap scenario. Furthermore, data-driven methods are sensitive to domain shift due to the variability of resolution, contrast in acquisition, pathology, and differences in anatomy. In this work, we propose a self-supervised SR technique to address anisotropic MR images with and without slice gap. We compare against competing methods and validate in both signal recovery and downstream task performance on two open-source datasets and show improvements in all respects. Our code publicly available at https://gitlab.com/iacl/smore.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="ZUO2023102285" class="col-sm-10"> <div class="title">HACA3: A unified approach for multi-site MR image harmonization</div> <div class="author"> Lianrui Zuo, Yihao Liu, Yuan Xue, <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, <a href="https://sremedios.github.io/" rel="external nofollow noopener" target="_blank">Samuel W. Remedios</a>, Savannah P. Hays, Murat Bilgel, Ellen M. Mowry, Scott D. Newsome, Peter A. Calabresi, Susan M. Resnick, Jerry L. Prince, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Aaron Carass' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">1 more author</span> </div> <div class="periodical"> <em>Computerized Medical Imaging and Graphics</em>, Apr 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.compmedimag.2023.102285" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.compmedimag.2023.102285" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:XiSMed-E-HIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The lack of standardization and consistency of acquisition is a prominent issue in magnetic resonance (MR) imaging. This often causes undesired contrast variations in the acquired images due to differences in hardware and acquisition parameters. In recent years, image synthesis-based MR harmonization with disentanglement has been proposed to compensate for the undesired contrast variations. The general idea is to disentangle anatomy and contrast information from MR images to achieve cross-site harmonization. Despite the success of existing methods, we argue that major improvements can be made from three aspects. First, most existing methods are built upon the assumption that multi-contrast MR images of the same subject share the same anatomy. This assumption is questionable, since different MR contrasts are specialized to highlight different anatomical features. Second, these methods often require a fixed set of MR contrasts for training (e.g., both T1-weighted and T2-weighted images), limiting their applicability. Lastly, existing methods are generally sensitive to imaging artifacts. In this paper, we present Harmonization with Attention-based Contrast, Anatomy, and Artifact Awareness (HACA3), a novel approach to address these three issues. HACA3 incorporates an anatomy fusion module that accounts for the inherent anatomical differences between MR contrasts. Furthermore, HACA3 can be trained and applied to any combination of MR contrasts and is robust to imaging artifacts. HACA3 is developed and evaluated on diverse MR datasets acquired from 21 sites with varying field strengths, scanner platforms, and acquisition protocols. Experiments show that HACA3 achieves state-of-the-art harmonization performance under multiple image quality metrics. We also demonstrate the versatility and potential clinical impact of HACA3 on downstream tasks including white matter lesion segmentation for people with multiple sclerosis and longitudinal volumetric analyses for normal aging subjects. Code is available at https://github.com/lianruizuo/haca3.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div id="9253710" class="col-sm-10"> <div class="title">SMORE: A Self-Supervised Anti-Aliasing and Super-Resolution Algorithm for MRI Using Deep Learning</div> <div class="author"> Can Zhao, <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, Dzung L. Pham, Peter A. Calabresi, Daniel S. Reich, and Jerry L. Prince </div> <div class="periodical"> <em>IEEE Transactions on Medical Imaging</em>, Apr 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TMI.2020.3037187" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/TMI.2020.3037187" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:fQNAKQ3IYiAC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>High resolution magnetic resonance (MR) images are desired in many clinical and research applications. Acquiring such images with high signal-to-noise (SNR), however, can require a long scan duration, which is difficult for patient comfort, is more costly, and makes the images susceptible to motion artifacts. A very common practical compromise for both 2D and 3D MR imaging protocols is to acquire volumetric MR images with high in-plane resolution, but lower through-plane resolution. In addition to having poor resolution in one orientation, 2D MRI acquisitions will also have aliasing artifacts, which further degrade the appearance of these images. This paper presents an approach SMORE based on convolutional neural networks (CNNs) that restores image quality by improving resolution and reducing aliasing in MR images. This approach is self-supervised, which requires no external training data because the high-resolution and low-resolution data that are present in the image itself are used for training. For 3D MRI, the method consists of only one self-supervised super-resolution (SSR) deep CNN that is trained from the volumetric image data. For 2D MRI, there is a self-supervised anti-aliasing (SAA) deep CNN that precedes the SSR CNN, also trained from the volumetric image data. Both methods were evaluated on a broad collection of MR data, including filtered and downsampled images so that quantitative metrics could be computed and compared, and actual acquired low resolution images for which visual and sharpness measures could be computed and compared. The super-resolution method is shown to be visually and quantitatively superior to previously reported methods</p> </div> </div> </div> </li> <li> <div class="row"> <div id="ZUO2021118569" class="col-sm-10"> <div class="title">Unsupervised MR harmonization by learning disentangled representations using information bottleneck theory</div> <div class="author"> Lianrui Zuo, <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, Yihao Liu, Yufan He, Scott D. Newsome, Ellen M. Mowry, Susan M. Resnick, Jerry L. Prince, and Aaron Carass </div> <div class="periodical"> <em>NeuroImage</em>, Apr 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.neuroimage.2021.118569" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.neuroimage.2021.118569" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:zYLM7Y9cAGgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>In magnetic resonance (MR) imaging, a lack of standardization in acquisition often causes pulse sequence-based contrast variations in MR images from site to site, which impedes consistent measurements in automatic analyses. In this paper, we propose an unsupervised MR image harmonization approach, CALAMITI (Contrast Anatomy Learning and Analysis for MR Intensity Translation and Integration), which aims to alleviate contrast variations in multi-site MR imaging. Designed using information bottleneck theory, CALAMITI learns a globally disentangled latent space containing both anatomical and contrast information, which permits harmonization. In contrast to supervised harmonization methods, our approach does not need a sample population to be imaged across sites. Unlike traditional unsupervised harmonization approaches which often suffer from geometry shifts, CALAMITI better preserves anatomy by design. The proposed method is also able to adapt to a new testing site with a straightforward fine-tuning process. Experiments on MR images acquired from ten sites show that CALAMITI achieves superior performance compared with other harmonization approaches.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="10.1007/978-3-030-78191-0_27" class="col-sm-10"> <div class="title">Information-Based Disentangled Representation Learning for Unsupervised MR Harmonization</div> <div class="author"> Lianrui Zuo, <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, Aaron Carass, Yihao Liu, Yufan He, Peter A. Calabresi, and Jerry L. Prince </div> <div class="periodical"> <em>In Information Processing in Medical Imaging</em>, Apr 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-78191-0_27" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-78191-0_27" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:TFP_iSt0sucC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Accuracy and consistency are two key factors in computer-assisted magnetic resonance (MR) image analysis. However, contrast variation from site to site caused by lack of standardization in MR acquisition impedes consistent measurements. In recent years, image harmonization approaches have been proposed to compensate for contrast variation in MR images. Current harmonization approaches either require cross-site traveling subjects for supervised training or heavily rely on site-specific harmonization models to encourage harmonization accuracy. These requirements potentially limit the application of current harmonization methods in large-scale multi-site studies. In this work, we propose an unsupervised MR harmonization framework, CALAMITI (Contrast Anatomy Learning and Analysis for MR Intensity Translation and Integration), based on information bottleneck theory. CALAMITI learns a disentangled latent space using a unified structure for multi-site harmonization without the need for traveling subjects. Our model is also able to adapt itself to harmonize MR images from a new site with fine tuning solely on images from the new site. Both qualitative and quantitative results show that the proposed method achieves superior performance compared with other unsupervised harmonization approaches.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="Dewey1396" class="col-sm-10"> <div class="title">MTT and Blood-Brain Barrier Disruption within Asymptomatic Vascular WM Lesions</div> <div class="author"> B.E. Dewey, X. Xu, L. Knutsson, A. Jog, J.L. Prince, P.B. Barker, P.C.M. Zijl, R. Leigh, and P. Nyquist </div> <div class="periodical"> <em>American Journal of Neuroradiology</em>, Apr 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3174/ajnr.A7165" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.3174/ajnr.A7165" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:JV2RwH3_ST0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>BACKGROUND AND PURPOSE: White matter lesions of presumed ischemic origin are associated with progressive cognitive impairment and impaired BBB function. Studying the longitudinal effects of white matter lesion biomarkers that measure changes in perfusion and BBB patency within white matter lesions is required for long-term studies of lesion progression. We studied perfusion and BBB disruption within white matter lesions in asymptomatic subjects.MATERIALS AND METHODS: Anatomic imaging was followed by consecutive dynamic contrast-enhanced and DSC imaging. White matter lesions in 21 asymptomatic individuals were determined using a Subject-Specific Sparse Dictionary Learning algorithm with manual correction. Perfusion-related parameters including CBF, MTT, the BBB leakage parameter, and volume transfer constant were determined.RESULTS: MTT was significantly prolonged (7.88 [SD, 1.03] seconds) within white matter lesions compared with normal-appearing white (7.29 [SD, 1.14] seconds) and gray matter (6.67 [SD, 1.35] seconds). The volume transfer constant, measured by dynamic contrast-enhanced imaging, was significantly elevated (0.013 [SD, 0.017] minutes-1) in white matter lesions compared with normal-appearing white matter (0.007 [SD, 0.011] minutes-1). BBB disruption within white matter lesions was detected relative to normal white and gray matter using the DSC-BBB leakage parameter method so that increasing BBB disruption correlated with increasing white matter lesion volume (Spearman correlation coefficient = 0.44; P &lt; .046).CONCLUSIONS: A dual-contrast-injection MR imaging protocol combined with a 3D automated segmentation analysis pipeline was used to assess BBB disruption in white matter lesions on the basis of quantitative perfusion measures including the volume transfer constant (dynamic contrast-enhanced imaging), the BBB leakage parameter (DSC), and MTT (DSC). This protocol was able to detect early pathologic changes in otherwise healthy individuals.cSVDcerebrovascular small-vessel diseaseDCEdynamic contrast-enhancedGdgadoliniumK2BBB leakage parameterKtransvolume transfer constantWMLwhite matter lesion</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div id="10.1007/978-3-030-59728-3_70" class="col-sm-10"> <div class="title">A Disentangled Latent Space for Cross-Site MRI Harmonization</div> <div class="author"> <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, Lianrui Zuo, Aaron Carass, Yufan He, Yihao Liu, Ellen M. Mowry, Scott Newsome, Jiwon Oh, Peter A. Calabresi, and Jerry L. Prince </div> <div class="periodical"> <em>In Medical Image Computing and Computer Assisted Intervention – MICCAI 2020</em>, Apr 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-59728-3_70" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-59728-3_70" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:bFI3QPDXJZMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Accurate interpretation and quantification of magnetic resonance imaging (MRI) is vital to medical research and clinical practice. However, lack of MRI standardization and differences in acquisition protocols often lead to measurement inconsistencies across sites. Image harmonization techniques have been shown to improve qualitative and quantitative consistency between differently acquired scans. Unfortunately, these methods typically require paired training data from traveling subjects (for supervised methods) or assumptions about anatomical similarities between the populations (for unsupervised methods). We propose a deep learning-based harmonization technique with limited supervision for use in standardization across scanners and sites. By leveraging a disentangled latent space represented by a high-resolution anatomical information component (}}\backslashbeta }}β) and a low-dimensional contrast component (}}\backslashtheta }}θ), the proposed method trains a cross-site harmonization model using databases of multi-modal image pairs acquired separately from each of the scanners to be harmonized. In this manuscript, we show that by using T}}_1}}1-weighted and T}}_2}}2-weighted images acquired from different subjects at three different sites, we can achieve a stable extraction of }}\backslashbeta }}\betawith a continuous representation of }}\backslashtheta }}θ. We also demonstrate that this allows cross-site harmonization without the need for paired data between sites.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div id="DEWEY2019160" class="col-sm-10"> <div class="title">DeepHarmony: A deep learning approach to contrast harmonization across scanner changes</div> <div class="author"> <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, Can Zhao, Jacob C. Reinhold, Aaron Carass, Kathryn C. Fitzgerald, Elias S. Sotirchos, Shiv Saidha, Jiwon Oh, Dzung L. Pham, Peter A. Calabresi, Peter C.M. van Zijl, and Jerry L. Prince </div> <div class="periodical"> <em>Magnetic Resonance Imaging</em>, Apr 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.mri.2019.05.041" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.mri.2019.05.041" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=G_x76scAAAAJ&amp;citation_for_view=G_x76scAAAAJ:cFHS6HbyZ2cC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-N/A-4285F4?logo=googlescholar&amp;labelColor=beige" alt="N/A Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Magnetic resonance imaging (MRI) is a flexible medical imaging modality that often lacks reproducibility between protocols and scanners. It has been shown that even when care is taken to standardize acquisitions, any changes in hardware, software, or protocol design can lead to differences in quantitative results. This greatly impacts the quantitative utility of MRI in multi-site or long-term studies, where consistency is often valued over image quality. We propose a method of contrast harmonization, called DeepHarmony, which uses a U-Net-based deep learning architecture to produce images with consistent contrast. To provide training data, a small overlap cohort (n = 8) was scanned using two different protocols. Images harmonized with DeepHarmony showed significant improvement in consistency of volume quantification between scanning protocols. A longitudinal MRI dataset of patients with multiple sclerosis was also used to evaluate the effect of a protocol change on atrophy calculations in a clinical research setting. The results show that atrophy calculations were substantially and significantly affected by protocol change, whereas such changes have a less significant effect and substantially reduced overall difference when using DeepHarmony. This establishes that DeepHarmony can be used with an overlap cohort to reduce inconsistencies in segmentation caused by changes in scanner protocol, allowing for modernization of hardware and protocol design in long-term studies without invalidating previously acquired data.</p> </div> </div> </div> </li> <li> <div class="row"> <div id="10.1117/12.2513089" class="col-sm-10"> <div class="title">Evaluating the impact of intensity normalization on MR image synthesis</div> <div class="author"> Jacob C. Reinhold, <a href="https://profiles.hopkinsmedicine.org/provider/blake-dewey/3192849" rel="external nofollow noopener" target="_blank">Blake E. Dewey</a>, Aaron Carass, and Jerry L. Prince </div> <div class="periodical"> <em>In Medical Imaging 2019: Image Processing</em>, Apr 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1117/12.2513089" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1117/12.2513089" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Image synthesis learns a transformation from the intensity features of an input image to yield a different tissue contrast of the output image. This process has been shown to have application in many medical image analysis tasks including imputation, registration, and segmentation. To carry out synthesis, the intensities of the input images are typically scaled—i.e., normalized—both in training to learn the transformation and in testing when applying the transformation, but it is not presently known what type of input scaling is optimal. In this paper, we consider seven different intensity normalization algorithms and three different synthesis methods to evaluate the impact of normalization. Our experiments demonstrate that intensity normalization as a preprocessing step improves the synthesis results across all investigated synthesis algorithms. Furthermore, we show evidence that suggests intensity normalization is vital for successful deep learning-based MR image synthesis.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Blake Dewey. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>